{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4e09d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements\n",
    "pip install kserve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688ef9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5ea277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "prompt = \"Write a poem about a dog\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1617a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "model_name = \"vllm-llama3-8b\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "data = {\n",
    "    \"model\": \"vllm-llama3-8b\",\n",
    "    \"prompt\": prompt,\n",
    "    \"max_tokens\": 100,\n",
    "    \"temperature\": 0\n",
    "}\n",
    "\n",
    "# To get base_url: \n",
    "# oc expose service vllm-llama3-8b-predictor\n",
    "# oc get route vllm-llama3-8b-predictor -n modelserving-demo -o jsonpath='{\"http://\"}{.spec.host}{\"\\n\"}'\n",
    "base_url = \"http://vllm-llama3-8b-predictor-modelserving-demo.apps.rosa.n1t3u2f3w1s0b1d.kkw2.p3.openshiftapps.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec177a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_response = requests.post(f\"{base_url}/v1/completions\", headers=headers, json=data)\n",
    "\n",
    "if infer_response.status_code == 200:\n",
    "    print(infer_response.json()[\"choices\"][0][\"text\"].strip())\n",
    "else:\n",
    "    print(\"Error:\", infer_response.status_code)\n",
    "    print(infer_response.text)\n",
    "print(\"Raw response: \", infer_response)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
